# 综合案例

## 搜狗统计案例

### 数据准备

### 编写语句

```python
	#1-创建SparkContext对象
    conf = SparkConf().setMaster('local[*]').setAppname('sougou')
    sc = SparkContext(conf = conf)
    
    #2-读取外部文件数据
    rdd_init = sc.textFile('file:///export/data/workspace/...')
    
    #3-过滤数据：保证数据不能为空，并让数据字段数量必须为六个
    rdd_filter = rdd_init.filter(lambda line: line.strip() != '' and len(line.split()) == 6)
    print(rdd_filter.count())
    
    #4-对数据进行切割，将数据放置到一个元组中：一行放置一个元组
    rdd_filter.map(lambda line: (
        line.split()[0],
    	line.split()[1],
    	line.split()[2][1,-1],
    	line.split()[3],
        line.split()[4],
        line.split()[5],
    ))
    
    #5-统计分析的处理
   	#5.1-需求1

    #5.2-需求2
	
    
    #5.3-需求3
    
    
    
```



